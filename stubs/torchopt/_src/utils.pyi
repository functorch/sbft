"""
This type stub file was generated by pyright.
"""

from typing import Dict, List, NamedTuple, Union

class _ModuleState(NamedTuple):
    params: List[Dict]
    visual_contents: Union[None, Dict] = ...


def stop_gradient(target): # -> None:
    """Stop the gradient for the input object.

    Since a tensor use :attr:`grad_fn` to connect itself with the previous computation graph, the
    back-propagated gradient will flow over the tensor and continue flow to the tensors that is
    connected by :attr:`grad_fn`. Some algorithms requires manually detaching tensors from the
    computation graph.

    Note that the :func:`stop_gradient` operation is in-place.

    Args:
        target: The target that to be detached from the computation graph, it could be a
            :class:`nn.Module`, :class:`torchopt.MetaOptimizer`, state of the
            :class:`torchopt.MetaOptimizer`, or just a plain list of tensors.
        inplace: If :data:`True`, the target will be detached in-place. if :data:`Frue`, this
            function will return a detached copy of the target. The in-place operation is fast and
            memory efficient but may raise back-propagation error.
    """
    ...

def extract_state_dict(mod, copy=..., *, with_buffer=..., enable_visual=..., visual_prefix=...): # -> _ModuleState | PyTree[Unknown] | tuple[Unknown, ...]:
    """Extract target state.

    Since a tensor use :attr:`grad_fn` to connect itself with the previous computation graph, the
    back-propagated gradient will flow over the tensor and continue flow to the tensors that is
    connected by :attr:`grad_fn`. Some algorithms requires manually detaching tensors from the
    computation graph.

    Note that the extracted state is a reference, which means any in-place operator will affect the
    target that the state is extracted from.

    Args:
        mod: It could be a :class:`nn.Module` or :class:`torchopt.MetaOptimizer`.
        with_buffer:
            Extract buffer together with parameters, this argument is only used if the input target
            is :class:`nn.Module`.
        enable_visual:
            Add additional annotations, which could be used in computation graph visualization.
            Currently, this flag only has effect on :class:`nn.Module` but we will support
            :class:`torchopt.MetaOptimizer` later.
        visual_prefix: Prefix for the visualization annotations.

    Returns:
        State extracted of the input object.
    """
    ...

def recover_state_dict(mod, state): # -> None:
    """Recover state.

    This function is compatible for the ``extract_state``.

    Note that the recovering process is not in-place, so the tensors of the object will not be
    modified.

    Args:
        mod: Target that need to recover.
        state: The recovering state.
    """
    ...

